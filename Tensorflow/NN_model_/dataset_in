import pandas as pd
import numpy as np
import tensorflow as tf
from project import features_manager as fm
from project import normalize_functions as nf
from project import input_builder as ib
from project import constants  as c


__version__ = "0.1.0"

__status__ = "Project"

############################## Description ##############################
# This object tries to make a fast and manipulated dataset used to the train and test step.
#
###################################################################







class Tmfl_datset ():

    def __init__(self,):
        self.training_examples = None
        self.training_targets = None
        self.validation_examples = None
        self.validation_targets= None

    # def __init__(self,path_file,n_test,dimensions):
    #     # self.file = path_file
    #     self.file = "/ANN/input_data/test2.csv"
    #     self.n_test = n_test


    def input_data(self,path_file):
        _dataset_original = pd.read_csv(path_file, sep=";", header=2)
        pd.options.display.float_format = '{:.4f}'.format

        _dataset = pd.DataFrame(_dataset_original.reindex(
            np.random.permutation(_dataset_original.index)))

        dataset_features_normalized = fm.preprocess_features(_dataset)
        dataset_features_normalized_vdd = fm.preprocess_features(_dataset)
        dataset_features_normalized = nf.normalize_x_scale(dataset_features_normalized)
        dies_selected, training_data, validation_data = ib.create_datasets(dataset_features_normalized, 4)

        print("Dies for training:  %s" % training_data.Die.unique())
        print("Dies for Validation:  %s" % validation_data.Die.unique())
        print("Dies selected %s" % dies_selected)
        validation_dataset_features_normalized = fm.preprocess_features(validation_data)


        self.dataset_examples = dataset_features_normalized[c.FEATURES[2:len(c.FEATURES)]]
        self.dataset_targets = dataset_features_normalized[c.TARGET]



        self.training_examples = training_data[c.FEATURES[2:len(c.FEATURES)]]
        self.training_targets = training_data[c.TARGET]

        self.validation_examples = validation_data[c.FEATURES[2:len(c.FEATURES)]]
        self.validation_targets = validation_data[c.TARGET]

        # print(self.training_examples.shape, self.training_targets.shape)

    def get_train_dataset(self,batch_size,num_epochs):

        training_input_fn = ib.my_input_fn_v2(self.training_examples,
                                           self.training_targets["F"],
                                                   batch_size=batch_size,
                                                   num_epochs=num_epochs,
                                                   shuffle=True )


        return training_input_fn

    def get_test_dataset(self,num_epochs):
        testing_input_fn =  ib.my_input_fn_v2(self.validation_examples,
                                                   self.validation_targets["F"],
                                                           num_epochs=num_epochs,
                                                           batch_size=self.validation_targets.shape[0],
                                                           shuffle=False)


        return testing_input_fn

    def get_all_dataset(self):
        all_input_fn = ib.my_input_fn_v2(self.dataset_examples,
                                                             self.dataset_targets["F"],
                                                             num_epochs=1,
                                                             batch_size=self.dataset_targets.shape[0],
                                                             shuffle=False)

        return all_input_fn



    def test_data (self):
        pass

    def design_prediction (self):
        pass

